"""Main experiment file."""

import json
import time

import click
from tqdm import tqdm

from data import gen_common, gen_taskc, get_experiment_dataset
from gen import get_response_google
from prompt import METHOD2_TEMPLATE_MULTICHOICE, QUERY_TEMPLATE_MULTICHOICE, PRIDE_TEMPLATE
from util import get_result_dir
from pride_method import create_pride_exp


def save_responses(
    model: str,
    prompt_method: str,
    requests: list[str],
    responses: list[dict],
    lang: str,
    subject: str,
    answer: int,
    index: int,
) -> None:
    """
    Save the responses to a jsonl file.
    """
    # Create the directory if it doesn't exist
    result_dir = get_result_dir(lang, subject, model, prompt_method)
    result_dir.mkdir(parents=True, exist_ok=True)

    # Save the requests to a jsonl file
    for request, response in zip(requests, responses):
        response["request"] = request
        response["answer"] = answer

    # Save the responses to a jsonl file
    with (result_dir / f"{index}.jsonl").open("w", encoding="utf-8") as f:
        # Write the responses to the file
        for response in responses:
            f.write(json.dumps(response, ensure_ascii=False) + "\n")


def format_request(
    question: str,
    choices: list[str],
    method: str = "cot",  # choices: "cot", "pride", "multilingual", "multichoice"
) -> str:
    """
    Format the request for the Gemini model.
    """

    if method == "cot":
        return QUERY_TEMPLATE_MULTICHOICE.format(
            Question=question,
            A=choices[0],
            B=choices[1],
            C=choices[2],
            D=choices[3],
        )
    if method == "pride":
        return PRIDE_TEMPLATE.format(
            Question=question,
            A=choices[0],
            B=choices[1],
            C=choices[2],
            D=choices[3],
        )
        pass
    if method == "multilingual":
        # TODO: Implement our proposed method 1, translate the question into multilingual and also shuffle the choices.
        pass
    if method == "multichoice":
        return METHOD2_TEMPLATE_MULTICHOICE.format(
            Question=question,
            A=choices[0],
            B=choices[1],
            C=choices[2],
            D=choices[3],
        )

    raise ValueError(f"Unknown method: {method}")


def get_request_text(
    question: str,
    choices: list[str],
    answer: int,
    prompt_method: str = "cot",
) -> list[str]:
    """
    Generate the request text for the Gemini model.
    Returns:
        The index of the return list is the index of the answer in the choices.
    When method is 'gt', the ground truth shuflling is applied.
    When method is 'fb', the forward-backward shuffling is applied.
    """
    # Shuffle the choices based on the gold answer.
    answer = choices[answer]
    non_answer_choices = [choice for choice in choices if choice != answer]
    if len(non_answer_choices) != 3:
        non_answer_choices.append("")
    shuffled_choices = [
        [answer] + non_answer_choices,
        [non_answer_choices[2], answer] + non_answer_choices[:2],
        [
            non_answer_choices[1],
            non_answer_choices[2],
            answer,
            non_answer_choices[0],
        ],
        [
            non_answer_choices[2],
            non_answer_choices[1],
            non_answer_choices[0],
            answer,
        ],
    ]

    return [
        format_request(
            question=question,
            choices=choices,
            method=prompt_method,
        )
        for choices in shuffled_choices
    ]


def create_exp(
    dataset,
    lang: str,
    model="google",
    prompt_method="cot",
) -> None:
    """
    Create the experiment for the given dataset and language.
    """
    for i, (question, subject, choices, answer) in enumerate(
        tqdm(
            zip(
                dataset["question"],
                dataset["subject"],
                dataset["choices"],
                dataset["answer"],
            ),
            total=len(dataset["question"]),
        ),
    ):
        # check if the directory exists
        result_dir = get_result_dir(
            lang=lang,
            subject=subject,
            model=model,
            prompt_method=prompt_method,
        )
        file_path = result_dir / f"{i}.jsonl"
        if file_path.exists():
            print(f"File {file_path} already exists. Skipping...")
            continue

        start = time.time()

        requests = get_request_text(
            question,
            choices,
            answer,
            prompt_method=prompt_method,
        )

        responses = None
        if model == "google":
            responses = get_response_google(
                requests,
            )
        elif model == "local":
            from local_gen import get_response_local

            responses = get_response_local(
                requests,
            )

        save_responses(
            model=model,
            prompt_method=prompt_method,
            requests=requests,
            responses=responses,
            lang=lang,
            subject=subject,
            answer=answer,
            index=i,
        )
        end = time.time()
        if model == "google":
            if end - start < 60 / 15 * 4:
                time.sleep(16 - (end - start) + 2)


@click.command()
@click.option(
    "--model",
    type=click.Choice(["google", "local"]),
    default="google",
    help="Model to use for the experiment.",
)
@click.option(
    "--prompt_method",
    type=click.Choice(["cot", "pride", "multilingual", "multichoice"]),
    default="cot",
    help="Prompt method to use for the experiment.",
)
@click.option(
    "--exp",
    type=click.Choice(["common", "taskc"]),
    default="common",
    help="Experiment to run.",
)
def main(
    model: str,
    prompt_method: str,
    exp: str,
):
    """
    Main function to run the experiment.
    """
    # Generate common / taskc datasets
    datasets = gen_common() if exp == "common" else gen_taskc()

    print("Using model:", model)

    for lang, subject in tqdm(datasets):
        # Start the experiment
        print(f"Language: {lang}, Subject: {subject}")

        # Get the dataset
        dataset = get_experiment_dataset(lang, subject)

        # Start Inferencing
        if prompt_method == "pride":
           # 用 PriDe 的两阶段 debias 流程
           create_pride_exp(
               dataset,
               lang,
               model=model,
               # 这里 K=10 只是示例，你可以根据需要调整
               K=10,
           )
        else:
            create_exp(
                dataset,
                lang,
                model=model,
                prompt_method=prompt_method,
            )

    print("Experiment completed.")


if __name__ == "__main__":
    main()
